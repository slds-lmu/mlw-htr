{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (GPT2Config, PreTrainedTokenizerFast, Seq2SeqTrainer,\n",
    "                          Seq2SeqTrainingArguments, VisionEncoderDecoderConfig,\n",
    "                          VisionEncoderDecoderModel, ViTConfig, TrOCRProcessor,\n",
    "                          ViTImageProcessor, default_data_collator)\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file='/home/philko/Documents/Uni/WiSe2223/Consulting/mlw-consulting-project/models/tokenizer/MLW_Tokenizer.json')\n",
    "feature_extractor: ViTImageProcessor = ViTImageProcessor.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k'\n",
    ")\n",
    "image_processor: ViTImageProcessor = ViTImageProcessor.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_encoder = ViTConfig()\n",
    "config_decoder = GPT2Config()\n",
    "\n",
    "# Group architectures and define model\n",
    "config = VisionEncoderDecoderConfig.from_encoder_decoder_configs(\n",
    "    config_encoder, config_decoder\n",
    ")\n",
    "model = VisionEncoderDecoderModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "processor: TrOCRProcessor = TrOCRProcessor.from_pretrained(\n",
    "    \"microsoft/trocr-base-handwritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<CLS>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(\n",
    "    \"/home/philko/Documents/Uni/WiSe2223/Consulting/mlw-consulting-project/data/interim/lemmata_img/images/301450.jpg\"\n",
    ").convert(\"RGB\")\n",
    "pixel_values = image_processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "# autoregressively generate caption (uses greedy decoding by default)\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)\n",
    "generated_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_test = tokenizer\n",
    "model_test = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = {\n",
    "    'pad_token': '<PAD>',\n",
    "    'cls_token': '<CLS>',\n",
    "    'bos_token': '<|endoftext|>',\n",
    "    'eos_token': '<|endoftext|>',\n",
    "    'unk_token': '<|endoftext|>'}\n",
    "tokenizer_test.add_special_tokens(special_tokens_dict)\n",
    "model_test.config.decoder_start_token_id = tokenizer_test.cls_token_id\n",
    "model_test.config.pad_token_id = tokenizer_test.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
